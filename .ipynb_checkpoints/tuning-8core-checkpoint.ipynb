{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['task_1', 'task_3', 'task_5'], 1: ['task_2', 'task_4', 'task_6']}\n",
      "{'task_1': 0, 'task_2': 1, 'task_3': 0, 'task_4': 1, 'task_5': 0, 'task_6': 1}\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "class GpuSchedular:\n",
    "    def __init__(self, n_gpus=2):\n",
    "        self.n_gpus = 2\n",
    "        self.reset()\n",
    "        \n",
    "    def allocate(self, task_idx):\n",
    "        \"\"\"\n",
    "        负责给GPU分配任务，尽量使得GPU任务数量尽量平均。不考虑显存大小。只是平均分任务。\n",
    "        \"\"\"\n",
    "        assert(task_idx not in self.task2gpu)\n",
    "        n_tasks = [len(val) for key, val in self.gpu2tasks.items()]\n",
    "        idx = (np.array(n_tasks)*-1).argmax()  # 选择最小的\n",
    "        target = [i for i in self.gpu2tasks.keys()][idx] # 选择对应的gpu id\n",
    "        self.gpu2tasks[target].append(task_idx)\n",
    "        self.task2gpu[task_idx] = target\n",
    "        return target\n",
    "    \n",
    "    def reset(self):\n",
    "        self.gpu2tasks = {i: [] for i in range(self.n_gpus)}\n",
    "        self.task2gpu = {}\n",
    "    \n",
    "\n",
    "class TaskPool:\n",
    "    def __init__(self, n_pool=5, arg_type='long', n_gpu=2):\n",
    "        self.n_pool = n_pool\n",
    "        self.arg_type = arg_type\n",
    "        self.gpu_schedular = GpuSchedular(n_gpu)\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.best_param_dict = {}\n",
    "    \n",
    "    def collect_results(self, info):\n",
    "        \"\"\"\n",
    "        key, val ? \n",
    "        \"\"\"\n",
    "        return 0, 12\n",
    "    \n",
    "    def _worker(self, param_dict, gpu_id):\n",
    "        cmd = \"CUDA_VISIBLE_DEVICES={}\".format(gpu_id) + \" \" + self._cmd_body() + \" \" + self._paramdict2str(param_dict)\n",
    "        print (cmd + \"\\n\")\n",
    "        r = os.popen(cmd)\n",
    "        info = r.readlines()\n",
    "        return self.collect_results(info)\n",
    "        \n",
    "    def start(self, grid_param_dict):\n",
    "        \"\"\"\n",
    "        grad_param_dict: \n",
    "            'anchor_model: [4]'\n",
    "            'reg': [0.001, 0.01, 0.1]\n",
    "        \"\"\"\n",
    "        s = time.time()\n",
    "        for key, vals in grid_param_dict.items():\n",
    "            results = [None for _ in range(len(vals))]\n",
    "            with mp.Pool(self.n_pool) as p:\n",
    "                for idx, val in enumerate(vals):\n",
    "                    tmp_dict = copy.deepcopy(self.best_param_dict)\n",
    "                    tmp_dict.update({key:val})\n",
    "                    results[idx] = p.apply_async(self._worker, (tmp_dict, self.gpu_schedular.allocate(idx)))\n",
    "                \n",
    "                output_keys = [None for _ in range(len(vals))]\n",
    "                output_vals = [None for _ in range(len(vals))]\n",
    "                for idx, res in enumerate(results): \n",
    "                    output_keys[idx], output_vals[idx] = res.get()\n",
    "                self.gpu_schedular.reset()\n",
    "                \n",
    "                print (output_keys)\n",
    "                idx = np.array(output_keys).argmax()\n",
    "                print(idx)\n",
    "                print (\"Find Better {}={}: {}\".format(key, vals[idx], output_vals[idx]))\n",
    "                self.best_param_dict[key] = vals[idx]\n",
    "                \n",
    "        print ('Time: \\t', (time.time() - s), ' sec')\n",
    "        print (\"Best Parameters: \\n{}\".format(self.best_param_dict))\n",
    "\n",
    "    def _paramdict2str(self, dic):\n",
    "        params = []\n",
    "        slash = \"--\" if self.arg_type == \"long\" else \"-\"\n",
    "        for key, val in dic.items():\n",
    "            assert (type(key) == str)\n",
    "            params.append(slash + key)\n",
    "            params.append(str(val))\n",
    "        return \" \".join(params)\n",
    "    \n",
    "    def _cmd_body(self):\n",
    "        \"\"\"\n",
    "        将param_dict中的参数展开作为 --key val 的形式\n",
    "        \"\"\"\n",
    "        return \"head main.py\"\n",
    "        \n",
    "    \n",
    "class AnchorTaskPool(TaskPool):\n",
    "    def __init__(self, n_pool, arg_type):\n",
    "        super(AnchorTaskPool, self).__init__(n_pool, arg_type)\n",
    "        \n",
    "    def _cmd_body(self):\n",
    "        #return \"python main.py\"\n",
    "        return \"python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736 \"\n",
    "    \n",
    "    def collect_results(self, info):\n",
    "        parameter, result, result_reward, time_cost = '', '', '', ''\n",
    "        generate_info = \"\"\n",
    "        for line in info:\n",
    "            if 'anchor best performance: ' in line:\n",
    "                result = line\n",
    "            if 'final generated sample number' in line:\n",
    "                generate_info = line\n",
    "        if result != \"\": \n",
    "            r = eval(result.split(':')[1])\n",
    "        else:\n",
    "            r = (0,0,0,0)\n",
    "        return r[2], (result, generate_info)\n",
    "    \n",
    "    \n",
    "    \n",
    "# 单元测试\n",
    "gpu_schedular = GpuSchedular(2)\n",
    "assert (gpu_schedular.allocate('task_1') == 0)\n",
    "assert (gpu_schedular.allocate('task_2') == 1)\n",
    "assert (gpu_schedular.allocate('task_3') == 0)\n",
    "assert (gpu_schedular.allocate('task_4') == 1)\n",
    "assert (gpu_schedular.allocate('task_5') == 0)\n",
    "assert (gpu_schedular.allocate('task_6') == 1)\n",
    "print  (gpu_schedular.gpu2tasks)\n",
    "print  (gpu_schedular.task2gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=1 head main.py -n 4\n",
      "CUDA_VISIBLE_DEVICES=0 head main.py -n 1\n",
      "CUDA_VISIBLE_DEVICES=1 head main.py -n 2\n",
      "CUDA_VISIBLE_DEVICES=0 head main.py -n 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0, 0, 0, 0]\n",
      "0\n",
      "Find Better n=1: 12\n",
      "Time: \t 0.1392672061920166  sec\n",
      "Best Parameters: \n",
      "{'n': 1}\n"
     ]
    }
   ],
   "source": [
    "TaskPool(5, 'short').start({'n': [1,2,3,4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_grid_param_dict = {\n",
    "    'reg': [0.0001, 0.0005, 0.0025, 0.0125, 0.0625, 0.3, 1.5], \n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.5], \n",
    "    'embedding_dim': [10, 30, 50, 80, 100], \n",
    "    'f_embedding_dim': [10, 30, 50, 80, 100], \n",
    "    'temp': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0001\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.3\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0005\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0125\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0625\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 1.5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0.10649743044301481, 0.10716835668015093, 0.11154494472155796, 0.1063290527665436, 0.08680231870485475, 0.08928389409899146, 0.08088076079816194]\n",
      "2\n",
      "Find Better reg=0.0025: ('anchor best performance: [0.08258706467661692, 0.23215674264927993, 0.11154494472155796, 0.5104477611940299, 0.15322417658754045]\\n', '')\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025 --learning_rate 0.7\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025 --learning_rate 1.5\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025 --learning_rate 0.0001\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025 --learning_rate 0.001\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025 --learning_rate 0.3\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025 --learning_rate 0.1\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025 --learning_rate 0.5\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025 --learning_rate 0.01\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Office_Products/ --anchor_model 1 --intervener_batch_size 736  --reg 0.0025 --learning_rate 0.9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuning for anchor model \n",
    "task = AnchorTaskPool(12, 'long')\n",
    "task.start(anchor_grid_param_dict)\n",
    "#task.start(anchor_grid_param_dict) # for better initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Amazon_Instant_Video/ --anchor_model 2 --intervener_batch_size 700  --intervener_learning_rate 0.001\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Amazon_Instant_Video/ --anchor_model 2 --intervener_batch_size 700  --intervener_learning_rate 0.0001\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Amazon_Instant_Video/ --anchor_model 2 --intervener_batch_size 700  --intervener_learning_rate 0.3\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Amazon_Instant_Video/ --anchor_model 2 --intervener_batch_size 700  --intervener_learning_rate 0.7\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Amazon_Instant_Video/ --anchor_model 2 --intervener_batch_size 700  --intervener_learning_rate 0.01\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Amazon_Instant_Video/ --anchor_model 2 --intervener_batch_size 700  --intervener_learning_rate 0.5\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Amazon_Instant_Video/ --anchor_model 2 --intervener_batch_size 700  --intervener_learning_rate 0.1\n",
      "CUDA_VISIBLE_DEVICES=0 python main.py --data_path ./data/Amazon_Instant_Video/ --anchor_model 2 --intervener_batch_size 700  --intervener_learning_rate 1.5\n",
      "CUDA_VISIBLE_DEVICES=1 python main.py --data_path ./data/Amazon_Instant_Video/ --anchor_model 2 --intervener_batch_size 700  --intervener_learning_rate 0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuning for intervener model\n",
    "intervener_grid_param_dict = {\n",
    "    'intervener_learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.5], \n",
    "    'confidence': [-0.65, -0.66, -0.67, -0.68, -0.69, -0.70, -0.71, -0.72, -0.73, -0.74, -0.75],\n",
    "    'reg': [0.0001, 0.0005, 0.0025, 0.0125, 0.0625, 0.3, 1.5], \n",
    "    'temp': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.5], \n",
    "    'intervener_reg': [0.0001, 0.0005, 0.0025, 0.0125, 0.0625, 0.3, 1.5],\n",
    "}\n",
    "\n",
    "class IntervenerTaskPool(AnchorTaskPool):\n",
    "    def _cmd_body(self):\n",
    "        return \"python main.py --data_path ./data/Pet_Supplies/ --anchor_model 2 --intervener_batch_size 12000 \"\n",
    "    \n",
    "interver_task = IntervenerTaskPool(12, 'long')\n",
    "interver_task.start(intervener_grid_param_dict)\n",
    "# interver_task.start(intervener_grid_param_dict) # for better initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = 2\n",
    "{'confidence': -0.72, 'reg': 1.5, 'learning_rate': 0.1, 'intervener_learning_rate': 0.7, 'intervener_reg': 0.0625}\n",
    "Find Better intervener_reg=0.0625: ('anchor best performance: [0.06875, 0.31278115981240984, 0.10195958861400038, 0.50625, 0.20588865880038246]\\n', 'final generated sample number:  186\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchro = 4\n",
    "{'confidence': -0.72, 'reg': 1.5, 'learning_rate': 1.5, 'intervener_learning_rate': 0.01, 'intervener_reg': 0.0025}\n",
    "('anchor best performance: [0.068125, 0.3152714646464646, 0.10209192665994135, 0.5125, 0.20725451524634075]\\n', 'final generated sample number:  162\\n')\n",
    "\n",
    "anchor = 3\n",
    "('anchor best performance: [0.058125, 0.24450036075036072, 0.08501224776040953, 0.40625, 0.15270569128776265]\\n', 'final generated sample number:  205\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
